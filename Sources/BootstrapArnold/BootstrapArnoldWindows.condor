universe = vanilla

requirements = (OpSys == "WINDOWS") && (Arch =="X86_64") && ( \
               (machine == "KOUPY-PC.keenswh.com") || \
               (machine == "SWE-TEST.keenswh.com"))

# Restrict the set of worker machines that can be used for the job according to Input\nodelist.txt. 
# Use condor_status command to find out machine names. Append the following to the requirements above.
#              && ( \
#              (machine == "USER1-PC.keenswh.com") || \
#              (machine == "USER2-PC.keenswh.com") || \
#              (machine == "USER3-PC.keenswh.com"))

executable = RunScript.cmd

should_transfer_files = YES
when_to_transfer_output = ON_EXIT_OR_EVICT
job_max_vacate_time = 1

# Directory on the submit machine used to gather all the output produced by the job. All input 
# file paths shall be specified relative to the initialdir. The initialdir itself shall be specified
# relative to the folder in which this job script file is located.
initialdir = Results

# Custom macros for input file paths on the submit machine. Shall be either absolute or relative to the initialdir.
CORE_DIR = ../../core/core/release
CHARMD_DIR = ../../core/libs/charm/net-release/bin
INPUT_DIR = ../Inputs

log = log.$(Cluster).$(Process).txt

transfer_executable = True

# Input files to be transferred from submit machine to the flat scratch directory on the worker machine. 
# Paths shall be either absolute or relative to the initialdir. If directory path ends with '/', only its
# contents are transferred to scratch directory, otherwise the directory itself is transferred as well.
# Special care must be taken to avoid naming conflicts when files are copied into scratch directory.
transfer_input_files = $(CORE_DIR)/, $(CHARMD_DIR)/, $(INPUT_DIR)/, checkpoint

# Output files to be transferred from scratch directory on the worker machine to the initialdir on
# the submit machine. Same rules apply as with transfer_input_files. Additionally, if you leave it
# empty, all files generated on the worker machine are considered output and automatically transferred.
transfer_output_files = checkpoint

# Condor job is defined as a cluster of processes. Cluster is described and generated by the submit 
# file (e.g. this file). Each process is then generated by occurence of 'queue' command within the 
# submit file. To run the same process multiple times, just append the multiplier to 'queue' command 
# (e.g. 'queue 3'). Number shall be equal to the number of hosts in the Input\nodelist.txt.
queue 2
